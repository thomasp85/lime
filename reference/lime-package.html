<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>lime: Local Interpretable Model-Agnostic Explanations — lime-package • lime</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/lumen/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="lime: Local Interpretable Model-Agnostic Explanations — lime-package"><meta property="og:description" content="
When building complex models, it is often difficult to explain why
    the model should be trusted. While global measures such as accuracy are
    useful, they cannot be used for explaining why a model made a specific
    prediction. 'lime' (a port of the 'lime' 'Python' package) is a method for
    explaining the outcome of black box models by fitting a local model around
    the point in question an perturbations of this point. The approach is
    described in more detail in the article by Ribeiro et al. (2016) 
    &amp;lt;arXiv:1602.04938&amp;gt;."><meta property="og:image" content="https://lime.data-imaginist.com/logo.svg"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">lime</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.5.2.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    News
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li class="dropdown-header">Release notes</li>
    <li>
      <a href="https://www.data-imaginist.com/2018/lime-v0-4-the-kitten-picture-edition/" class="external-link">Version 0.4.0</a>
    </li>
    <li>
      <a href="https://www.data-imaginist.com/2017/announcing-lime/" class="external-link">Version 0.3.0</a>
    </li>
    <li class="divider">
    <li>
      <a href="../news/index.html">Change log</a>
    </li>
  </ul></li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/thomasp85/lime" class="external-link">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>lime: Local Interpretable Model-Agnostic Explanations</h1>
    <small class="dont-index">Source: <a href="https://github.com/thomasp85/lime/blob/HEAD/R/lime-package.r" class="external-link"><code>R/lime-package.r</code></a></small>
    <div class="hidden name"><code>lime-package.Rd</code></div>
    </div>

    <div class="ref-description">
    <p></p>
<p>When building complex models, it is often difficult to explain why
    the model should be trusted. While global measures such as accuracy are
    useful, they cannot be used for explaining why a model made a specific
    prediction. 'lime' (a port of the 'lime' 'Python' package) is a method for
    explaining the outcome of black box models by fitting a local model around
    the point in question an perturbations of this point. The approach is
    described in more detail in the article by Ribeiro et al. (2016) 
    &lt;arXiv:1602.04938&gt;.</p>
    </div>


    <div id="details">
    <h2>Details</h2>
    <p>This package is a port of the original Python lime package implementing the
prediction explanation framework laid out Ribeiro <em>et al.</em> (2016). The
package supports models from <code>caret</code> and <code>mlr</code> natively, but see
<a href="model_support.html">the docs</a> for how to make it work for any model.</p>
<p><strong>Main functions:</strong></p>
<p>Use of <code>lime</code> is mainly through two functions. First you create an
<code>explainer</code> object using the <code><a href="lime.html">lime()</a></code> function based on the training data and
the model, and then you can use the <code><a href="explain.html">explain()</a></code> function along with new data
and the explainer to create explanations for the model output.</p>
<p>Along with these two functions, <code>lime</code> also provides the <code><a href="plot_features.html">plot_features()</a></code>
and <code><a href="text_explanations.html">plot_text_explanations()</a></code> function to visualise the explanations
directly.</p>
    </div>
    <div id="references">
    <h2>References</h2>
    <p>Ribeiro, M.T., Singh, S., Guestrin, C. <em>"Why Should I Trust You?": Explaining the Predictions of Any Classifier</em>. 2016, <a href="https://arxiv.org/abs/1602.04938" class="external-link">https://arxiv.org/abs/1602.04938</a></p>
    </div>
    <div id="see-also">
    <h2>See also</h2>
    <div class="dont-index"><p>Useful links:</p><ul><li><p><a href="https://lime.data-imaginist.com">https://lime.data-imaginist.com</a></p></li>
<li><p><a href="https://github.com/thomasp85/lime" class="external-link">https://github.com/thomasp85/lime</a></p></li>
<li><p>Report bugs at <a href="https://github.com/thomasp85/lime/issues" class="external-link">https://github.com/thomasp85/lime/issues</a></p></li>
</ul></div>
    </div>
    <div id="author">
    <h2>Author</h2>
    <p><strong>Maintainer</strong>: Thomas Lin Pedersen <a href="mailto:thomasp85@gmail.com">thomasp85@gmail.com</a> (<a href="https://orcid.org/0000-0002-5147-4711" class="external-link">ORCID</a>)</p>
<p>Authors:</p><ul><li><p>Michaël Benesty <a href="mailto:michael@benesty.fr">michael@benesty.fr</a></p></li>
</ul></div>

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by <a href="https://data-imaginist.com" class="external-link">Thomas Lin Pedersen</a>, Michaël Benesty.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.6.</p>
</div>

      </footer></div>

  


  

  </body></html>

